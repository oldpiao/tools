当前版本：2.3.1

2.3.1
新增正则停用词库，可以使用正则规则去除停用词，允许设置停用词规则词典
完善了一下相关文档，后续还有一些优化要做，做完再进一步完善文档
当前版本为“发行版”，功能基本完备，模块可在不影响当前使用的情况下扩充

2.3.0
对各个模块整理，整体分为几大块
    + cut_text.py  # 文本切分模块
    + words.py  # 结果集处理模块，包含了对分词后的结果集的处理方法
    + __init__.py  # 基础分词模块
        + 带词性分词，将结果对象换成自定义的MyPair对象，同时可以选择使用POSWords存储结果集
        + 使用正则的词性分词，在分词前先用正则分词，效率会因为正则过多而降低
    + segments  # 分词后对此的处理方法集, 可以完成大部分分词后的处理功能，可以持续完善
    + 删除control模块，项目改为独立模块组合使用的模式，不再刻意在某处集成了

2.2.1
新增了一些小模块，新增了业务模块用于新词发现，不属于模块本身，但属于模块应用，
同时发现应该将分词和后面处理模块分开来，可以更灵活的使用，之后再次更新模块时可以进行此操作
但要注意尽量与方式兼容

2.2.0
完成审计问题新词发现的主要代码，后面还需加入过滤模块，过滤分的不好的词
加入计算词信息的方法，可以计算一批分词结果的词频，TF-IDF等信息

2.1.0
修改词性匹配规则允许大写字母和@符出现
新增auto词性，会识别匹配到的词组中的最后一个词的词性
新增词性前缀功能，使用@符分开，可以在保留词性意义的同时区分分词，且支持“前缀@auto”
新增MeanAndTag、MeanOrTag可以同时用词义和词性选词

2.0.0
修复一系列bug
    + {2,}方法需要匹配至少三个
    + 匹配成功没有初始化规则参数，导致之后匹配出错
    + ...
优化规则切分功能，现在可以用"\/"转义"/"
新增正则方式匹配词义和词性，具体规则使用在“help/结合词性和词义的分词法研究.txt”中已更新

1.5.5
新增判断wn,rn长度，由于此处有可能会存在字符超限的情况一般存在于wn中

1.5.4
将项目的日志模块替换成my_log，且相应的更改settings.py中的配置，该修改使不同项目间日志不会互相影响

1.5.3
更新words.py中的POSTWord的_2str2方法,将分割符作为变量传入默认为/，代替_2str3的功能，并修改相关方法

1.5.2版本
settings.py中加入外层项目路径ROOT_DIR_P,目前应该用不到
删除SVN中老旧的代码，该部分代码的存储位置已经改变

1.5.1版本
更新words.py中的POSTWord的judge1方法，将判断规则由判断词性列表flags改为使用正则判断词性re_flag，
    并同时修改select_words的相关参数，与已使用的样例中的参数
修改程序结构，将项目模块化，目前项目主要代码在项目同名目录下，并对所有模块自建库的引用前加上该层路径

1.4.1版本
修复words.py中POSWords()中的deal_word()方法中的bug，之前的写法会导致原数据被改变，
    并在该方法中加入返回None时删除该词的操作,传参由原本的传word.word改为直接传word对象；
words.py中re_symbol正则规则中加入对空格的识别，程序会将空格当成句子的结束标识使用，用于分隔不同句子中的词；
修改main.py，使用第三套处理流程(只要自定义分词)处理了数据库中存储的审计问题，并将处理结果存入Excel。


1.4版本
完成非贪心匹配功能: ?；
完成动态规划算法，解决了类似"你*/你+"这类规则匹配失败的bug；
将正则算法改名为match，因为功能与re的match相同；
将贪心/非贪心算法研究过程的文档补全(只有流程)


1.3版本
新增固定数量匹配功能,例: 你好{3}/n{4}
新增可变数量匹配功能,例: 你好{3,5}/n{0,4}
将*+{3}{1,4}?等功能从rule.py/SplitRules()类中移动到judge.py中,并转变成类,RuleXXX中实例化使用
新增正则匹配判断标准-2、3,用于之后将添加的非贪婪匹配功能
    -2  # 未判断是否匹配成功，且按匹配失败处理，但在之后如有需要可以继续使用该规则往后匹配（非贪婪）
    -1  # 匹配失败
    0  # 匹配失败，继续使用该词和后续规则匹配
    1  # 匹配成功
    2  # 匹配成功，且继续使用该字段匹配（贪婪）
    3  # 匹配成功，但不再使用该字段继续匹配，且之后如有需要可以继续用该规则继续往后匹配（非贪婪）


1.2版本
新增通配符./；
新增数字识别功能避免个别情况下单个数字词性被识别成x的问题，可以使用该功能代替数词词性m使用；
将一些功能实现位置进行了修改，将+*实现方式进行了微调，修复一个bug；
修复测试用例由于新增功能产生的bug。


1.1版本
审计问题分词第一版：
1、目前支持的分词方式:
1.1 自定义词库
1.2 停用词
1.3 特殊符号(书名号内的认为是一个词)
1.4 正则取词(只会取首次规则匹配成功时的正则匹配结果作为取词结果)
1.5 词性正则等分词方式
2 目前支持的数据接入方式
内置了Excel、MySQL、数据存取接口，可以方便的处理其中的数据，其他数据格式可以自行实现
3 框架的扩展性设计
3.1 允许自定义业务模型，选择需要的分词方式。
3.2 允许对分词结果进行二次处理，如结果去重，对分的不好的词二次加工(传入加工方法即可)

4 词性正则目前支持的功能
4.1 词义识别: 通过词义匹配内容
4.2 词性识别: 通过词性匹配内容
4.2.1 词性精确匹配: 精确匹配词性
4.2.2 词性模糊匹配: 匹配词性前n个字符是否与规则中的词性相同
4.3 特殊符号匹配
4.3.2 *号: 匹配任意个字符
4.3.3 +号: 匹配多个字符
注: 当前版本规则使用/分隔，且未使用转义字符，且规则中如遇到m*/m+用于匹配12/m时会匹配不到，因此有此类需求时需要注意。
 